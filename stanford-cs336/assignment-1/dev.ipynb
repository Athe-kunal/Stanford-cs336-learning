{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## UNDERSTANDING UNICODE\n",
    "\n",
    "1. `chr(0)` returns `'\\x00'` which is the null character\n",
    "\n",
    "2. `__repr__` renders chr(0) as a null character (empty string) in the stdio, but unicode renders into a string object with place holder characters\n",
    "\n",
    "3. When rendered in a string, it is represented as `x00`, but with print it renders in stdio, hence empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this text is \\x00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this text is \" + chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this text is \u0000\n"
     ]
    }
   ],
   "source": [
    "print(\"this text is \" + chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"this text is \" + chr(0)\n",
    "\n",
    "len(s), len(\"this text is \") #so it does add to the length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are no out of distribution as each sequence of characters can be represented as list of integers\n",
    "\n",
    "1. UTF-8 is preferred because it is more byte-efficient and covers all the ASCII characters, emojis. Most of the dataset are stored in UTF-8, hence it is compatible to train too\n",
    "\n",
    "2. Some UTF-8 characters use multiple bytes, but as this is decoding one byte at a time, it is erroneous. It should decode all at once\n",
    "\n",
    "3. é decodes into two bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello there'\n"
     ]
    }
   ],
   "source": [
    "test_str = \"hello there\"\n",
    "s = test_str.encode(\"utf-8\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello\\x00 there      '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"hello\\x00 there      \"\n",
    "s = test_str.encode(\"utf-8\")\n",
    "\"\".join([bytes([k]).decode(\"utf-8\") for k in list(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n"
     ]
    }
   ],
   "source": [
    "print(bytes([104, 101, 108, 108]).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'h'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([104,101])\n",
    "bytes([104])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytests_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mbytes\u001b[39m([b]).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdecode_utf8_bytests_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\x00\u001b[39;49;00m\u001b[33;43mhelloé\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytests_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytests_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "def decode_utf8_bytests_to_str_wrong(bytestring: bytes) -> str:\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "decode_utf8_bytests_to_str_wrong(\"\\x00helloé\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226, 130, 172]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"€\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([226])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[195, 169]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('é'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBLEM 3\n",
    "\n",
    "### NOTES\n",
    "\n",
    "* Our initial vocabulary size is 256\n",
    "\n",
    "* We pre-tokenize the dataset to break them into characters, else it will treat `dog` and `dog!` differently\n",
    "\n",
    "* If we don't pre-tokenize, then everytime we merge, we have to count the occurences again. If you pre-tokenize, and let's say you have three bytes [1,2,3]. Suppose [1,2] occur many times, and you merge them to 4. So now it is [4,3]. But you still know the count of 4, which is the total count of [1,2], it is additive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "s = list(re.finditer(PAT, \"hello how are you doing, ज़रूर! यहाँ एक वाक्य है हिंदी में:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0].span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104, 101, 108, 108, 111]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('hello'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import regex as re\n",
    "\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "txt_file = \"/Users/athekunal/Desktop/Stanford-cs336/Stanford-cs336-learning/stanford-cs336/data/TinyStoriesV2-GPT4-valid.txt\"\n",
    "\n",
    "def convert_to_bytes(text: str) -> list[int]:\n",
    "    bytes_list: list[int] = []\n",
    "    for match in list(re.finditer(PAT, text)):\n",
    "        bytes_list.extend(list(text[match.span()[0]:match.span()[1]].encode('utf-8')))\n",
    "    return bytes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from typing import TypeAlias\n",
    "\n",
    "KeyBytes: TypeAlias = tuple[int, ...]\n",
    "BytesCount: TypeAlias = int\n",
    "\n",
    "a = \"low low low low low\"\n",
    "b = \"lower lower widest widest widest\"\n",
    "c = \"newest newest newest newest newest newest\"\n",
    "def convert_to_bytes(text: str) -> collections.defaultdict[KeyBytes, BytesCount]:\n",
    "    bytes_dict: collections.defaultdict[KeyBytes, BytesCount] = collections.defaultdict(\n",
    "        int\n",
    "    )\n",
    "    for match in list(re.finditer(PAT, text)):\n",
    "        bytes_key = tuple(list(match.group().encode(\"utf-8\")))\n",
    "        # group by two successive bytes and make the count, to reduce one less iteration\n",
    "        for i in range(len(bytes_key) - 1):\n",
    "            bytes_dict[(bytes_key[i], bytes_key[i + 1])] += 1\n",
    "    return bytes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(108, 111): 2,\n",
       "             (111, 119): 2,\n",
       "             (119, 101): 2,\n",
       "             (101, 114): 2,\n",
       "             (32, 108): 1,\n",
       "             (32, 119): 3,\n",
       "             (119, 105): 3,\n",
       "             (105, 100): 3,\n",
       "             (100, 101): 3,\n",
       "             (101, 115): 3,\n",
       "             (115, 116): 3})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_bytes(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_dict: collections.defaultdict[KeyBytes, BytesCount] = collections.defaultdict(\n",
    "        int\n",
    "    )\n",
    "for match in list(re.finditer(PAT, b)):\n",
    "    # bytes_key = tuple(list(match.group().encode(\"utf-8\")))\n",
    "    bytes_key = tuple(match.group().encode(\"utf-8\"))\n",
    "    bytes_dict[bytes_key]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(108, 111, 119, 101, 114): 1,\n",
       "             (32, 108, 111, 119, 101, 114): 1,\n",
       "             (32, 119, 105, 100, 101, 115, 116): 3})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VocabDict: TypeAlias = collections.defaultdict[KeyBytes, BytesCount]\n",
    "\n",
    "vocab_dict: VocabDict = collections.defaultdict(int)\n",
    "\n",
    "for bd_key, bd_val in bytes_dict.items():\n",
    "    for i in range(len(bd_key)-1):\n",
    "        vocab_dict[(bd_key[i], bd_key[i+1])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([((108, 111), 2),\n",
       "             ((111, 119), 2),\n",
       "             ((119, 101), 2),\n",
       "             ((101, 114), 2),\n",
       "             ((32, 108), 1),\n",
       "             ((32, 119), 1),\n",
       "             ((119, 105), 1),\n",
       "             ((105, 100), 1),\n",
       "             ((100, 101), 1),\n",
       "             ((101, 115), 1),\n",
       "             ((115, 116), 1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "sorted_dict = OrderedDict(sorted(vocab_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((108, 111), 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top1 = max(vocab_dict.items(), key=lambda item: item[1])\n",
    "top1[0], top1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (108, 111, 119, 101, 114, 108,114, 108,111)\n",
    "b = (108,111)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 111, 119, 101, 114, 108, 114, 108, 111)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_all_subsequences(a, b, curr_max_vocab):\n",
    "    if b == ():\n",
    "        return a\n",
    "    n, m = len(a), len(b)\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i <= n - m:\n",
    "        if a[i:i+m] == b:\n",
    "            result.append(curr_max_vocab)\n",
    "            i += m\n",
    "        else:\n",
    "            result.append(a[i])\n",
    "            i += 1\n",
    "    # Append any remaining elements at the end (if b doesn't reach the end)\n",
    "    result.extend(a[i:])\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "replace_all_subsequences(a,(),66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
